\documentclass[11pt]{article}
\input{reviewing.tex}

\begin{document}

\title{PErsoNal Genome QUery IN healthcare and clinical practice (PENGQUIN)}
\author[1,2]{Elias Crum}[
orcid=0009-0005-3991-754X,
email=elias.crum@ugent.be
]

\maketitle

\section{1. Rationale and positioning with regard to the state-of-the-art}
\textit{Elaborate the scientific motivation for the project proposal based on scientific knowledge gaps, and the issues and problems that you want to solve with this project. Concisely describe the related international state of the art, with reference to scientific literature. Indicate why the execution of the proposed strategic basic research is important. Position your project in relation to ongoing national and international research.} 

\rt{This is a very long section (probably too long). Could you split it up into subsections? (see my proposal as example.)}

\rt{Most of the text currently focuses on motivation (which is needed of course), but I think it can be shortened to about 0,5-1 page. What is missing, is a a discussion of the state-of-the-art research in this area, what the precise open problems are, and how you will solve these problems.}

\textbf{Introduciton}
As our understanding of genomics deepens, the role of Personal Genome Sequencing (PGS) in healthcare becomes increasingly vital. 
At the time of writing, there are multiple domains of clinical practice where patient personal genomic sequence (PGS) data is used to inform medical decision making[c,c]. 
For over a decade, PGS data has been poised to be scaled to generalized clinical practice, but at present this is largely not the case[c]. 
--! There are many problems that need to be solved and few attractive state-of-the-art solutions that solve them. !--
My proposed project aims to address one group of challenges inhibiting widespread clinical usage of PGS data -- those presented by the digital PGS data storage and access. 
For clinical practice, the key concerns related to PGS data are presented by three major constituents of the clinical ecosystem, those of the \textbf{patient, clinician, and healthcare administration}. 
Assessment of the current state-of-the-art as well as ways in which improvements could be made are determined along these three main axes.

From \textbf{all three perspectives}, privacy is of the utmost importance. 
PGS data, like other personal data, is by nature private and there is open debate regarding the degree to which patients should be able to control their own personal medical data[c,c]. 
Legally, within the European Union, a core tenant of current personal data usage is transparency[c]. 
Protections for citizens relating to sensitive personal data are codified in the European Union\textquotesingle s General Data Protection Regulation (GDPR) law since 2018[c]. 
PGS data, along with other health-related data, is categorized as “sensitive” data in the GDPR, carrying with it the strictest privacy safeguards. 
Notably, privacy is prioritized in the currently used systems, but improvements can still be made as centralized databases are cited to be prone to data leaks and ransomware attacks[c]. 

From the perspective of \textbf{the patient}, awareness and control over their personal data usage is an additional consideration that the current system does not do much to address. 
As established by the GDPR, technical infrastructure designed for the storage and accessing of PGS data requires special attention to methodologies that address patient control and/or transparency over usage of their data. 
Because of the architecture of centralized databases, granular permissions for specific subsets of sensitive data are challenging to implement yet could allow for a patient to view their own PGS data, thus improving their connection to their own personal data. 
Additionally, policy implementations such as patient ability to view and/or approve or deny consent to PGS data usage for specific instances, rather than a blanket consent at time of collection, will improve the patient\textquotesingle s involvement in how their data is used. 

From the perspective of \textbf{the clinician}, being able to access patient data, share patient data with providers outside one medical institution\textquotesingle s system, and not need to worry about data interoperability with biomedical tools, applications, or user interfaces is crucial. 
Data interoperability challenges emerge from the complex process of generating and storing PGS data as well as the large size of these datasets. 
The average human genome is slightly over 3 billion base pairs in length (3 Gbp)[c]. 
During a whole genome sequencing workflow, various sequence formats, that offer different sets of information, such as FASTQ[c], SAM/BAM/CRAM[c,c], VCF[c], and others are produced. 
With respect to clinical practice, the most useful of these files is the VCF file[c]. 
VCF files are typically between 100-1000s MB (0.1-1 GB) in size within computer memory when compressed and represent ~106 nucleotide positions of an individual\textquotesingle s PGS. 
While these data formats are widely considered the “standard” for genomic data, often the organization-specific directory structure and file naming protocol makes PGS data non-interoperable between databases.

From the perspective of \textbf{healthcare administration}, the cost of generating, storing, and maintaining patient PGS data, with the necessary privacy protections and monitoring, is nontrivial. 
Additionally, due to the preeminent centralized relational database structure utilized by healthcare institutions to maintain privacy of patient data, data sharing between institutions is very rarely practiced. 
The result is that institutions are responsible for re-generating PGS data for patients from out-of-network regardless of whether they may have an already generated genome sequence at another institution. Such data duplication represents unnecessary inefficiency that costs both the patient and institution, especially due to the heavy computational demands in generating PGS data and the high storage demands for the large PGS data files produced. 
During the life of that data, the hospital system that maintains the storage is also responsible for preserving the privacy of that information, which is becoming more and more difficult and costly for centralized databases due to increased incidence of ransomware attacks[c] and sensitive data leaks[c]. 


\textbf{Medical Motivations for PGS data in Cinical Practice}
For my proposed project to have an immediate impact on medical practice, PGS data use cases must both exist and exhibit improved outcomes compared to current practices that do not utilize PGS data. 
At present, there are three major medical fields that preliminarily show readiness for and benefit from greater use of PGS data, these being drug development and prescription, cancer diagnosis and treatment, and rare genetic disease identification and treatment.

Genomic variation has been shown to impact many aspects of drug prescription and treatment efficacy[c]. More recently, genomics has also become informative for new drug development[c]. 
In relation to clinical practice, many studies have documented genotype correlation with unintended drug responses for commonly prescribed drugs such as warfarin, ..., ..., etc. 
Clinically testing for patient genetic predisposition to non-responsiveness or heightened risk of side effects could encourage optimal treatment planning and dosing leading to improved clinical outcomes. 
Furthermore, PGS has the potential to help predict, better understand, and inform optimal drug treatment plans for patients with various diseases, and represents significant improvement over the one-size-fits-all, trial and error approach popularly practiced[c]. 
For cancer patients, the use of PGS data has been shown to similarly augment existing strategies of diagnosis and treatment. Studies have established that PGS data analysis can improve tumor diagnosis capabilities, development of targeted, personalized therapies, and allow for the development of more effective treatments[c]. 
Rare genetic diseases are one of the most established areas of medicine that PGS data has proved particularly useful in improving disease identification and treatment. 
Because an estimated 80\% of rare diseases are of genetic origin[c], and patients searching for diagnosis and proper treatment commonly undergo years of testing at more than one institution[c], new approaches for using and sharing PGS data are merited. 
It is also crucial to note that PGS is not devoid of challenges, including the potential overinterpretation of results due to a limited understanding of contextual information and the risk of genetic discrimination[c]. 
As with other cutting-edge technologies, there is much governance and technological development still needed for widespread use of PGS data for clinical care. 
With advancements being made consistently, such large scale adoption is not too distant.


\textbf{Current State of the Art -- Clinical}
As discussed above, there are some current use cases for PGS data clinical workflows, and thus, state-of-the-art systems established for  patient PGS data storage and access. 
Importantly, like other health data, clinical PGS data is stored using an \underline{institution-centric approach}. 
This strategy is characterized by the hospital or hospital system isolating all its stored data into one or more centralized databases that are governed and maintained solely by the owner institution. 
Here, centralized storage is defined as the structural organization of a data store, establishing that a single node, the system that hosts the physical data storage, has control over managing database content, access, and permissions. 
With this system, healthcare institutions prioritize patient data privacy over all other digital data storage conditions. 
This method of data storage prioritizes patient data security and access only for authorized users within the institution\textquotesingle s internal network. 
Crucially, this institution-centric data storage architecture, by design, allows for little to no accessibility for users or data usage requests that originate outside of the institution\textquotesingle s network, largely due to the organizational design of such centralized data storage systems. 
With the enlarged threat of hacking, phishing, and login credential compromisation that seems to only be increasing[c], hospitals and institutions that maintain patient PGS data are forced to enact tighter regulation over data access within their institution, severely limit outside institution access, and increase the in-house cyber security staff or pay for external companies to handle such security audits.  
Due to this isolation of patient PGS data to a single institution, data duplication leading to increased storage and data generation costs, severely limited patient data usage transparency, and severely limited potential for data sharing are observed. 
Collectively, these state-of-the-art approaches to PGS data storage inhibit the scalability of PGS data usage in the above discussed clinical applications due to raising PGS usage costs.

\textbf{Current State of the Art -- Academic Reserach and Consumer Market}
Apart from the current practices within healthcare institutions, other approaches for consumer access to their PGS data by private companies, PGS data sharing between research institutions, and general health data interoperability initiatives by multi-institution consortiums have been innovating the ways PGS data is stored and shared. 

Private companies, such as 23andMe, Ancestry.com, Sequencing.com, and others, offer consumption-centered genomic products such as ancestry profiles, health risk screenings, and rare-disease management guidelines among other emerging services. 
Such services have highlighted a public interest in being able to see and access their PGS data as well as learn useful things about themselves from it.
This emerging market reflects that consumers are keen to be able to access their PGS data, or at least use such data to know more about themselves. 
At the same time, innovation in this niche is not situated to handle the challenges presented by PGS data in clinical practice. 
Between similar centralized data storage approaches to hospital systems and large data leaks for companies like 23andMe in recent years, the prospect of existing companies offering solutions attractive enough to convince consumers or hospital systems to adopt a new system is unlikely. 

In the realm of academic reserach, the development of infrastructure that allows for sharing of genome data between institutions has gained traction recently. 
Due to reasons related to patient data privacy preservation, data is predominantly anonymized for sharing to be admissible. 
Initiatives such as OHDSI OMOP, HL7 FHIR, GA4GH Beacons, and others are building the infrastructure and establishing the interoperability standards necessary for between institution data sharing in this manner. 
The major drawbacks of these proposed solutions are, (a) the requirement that data must be anonymized for true sharing or, (b) control of data analysis is relinquished to the data\textquotesingle s home institution, thereby establishing federated networks of hospital data for data discoverability, but restricting actual access to such data for privacy reasons.

Despite great progress in research and consumer domains, advancements in state-of-the-art infrastructure and standards are not directly translatable to clinical practice due to various cinically unique demands detailed in the introduction. 

\textbf{Alternative Solutions}
A conceptual approach that offers a solution for the current challenges in data privacy, accessibility, and interoperability is moving away from an institution-centric model for PGS data storage and toward a citizen-centric one. More broadly, initiatives that exist in the health data domain are advocating for a similar change in technological philosophy. While this movement is still in its early stages, calls for leveraging decentralized storage technologies such as Solid, ..., ..., or Block Chain, have been proposed[c]. While there is still much work to be done before these fledgling technologies could be applied in practice, such approaches to PGS data storage offer great promise because of their ability to offer citizen-centric storage while also hosting the building blocks for features such as consent-driven data sharing, granularized data policy enforcement, stored data representation as Linked Data, and authorized data access over the web to just name some possibilities. 

Despite there being no real options for clinical PGS data sharing at present, there is also a conspicuous gap in the current scientific discourse around the development and implementation of such a infrastructure for personal genome data sharing for clinical use. 
This gap underscores the necessity of the proposed doctoral research project.
Our aim is to develop Personal Genome Pods using the Solid protocol[c], a set of technical specifications that enables decentralized data storage and infrastructure for data privacy preservation alongside increased sharing capabilities.  
I envisage that this project will significantly contribute to the field of personalized medicine and clinical genomic research by empowering individuals to utilize their personal genomes in healthcare and clinical practice in a manner that reinforces their autonomy and privacy. 
My project described here will aim to establish the feasibility of using decentralized storage technologies for PGS data storage and sharing with the hope that it results in direct translation into a product and/or acts as the schematic upon which future products are based. 


\section{2. Scientific research objective(s)}
\textit{Describe explicitly the scientific objective(s) and the research hypothesis. Explain whether and how the research is specifically challenging and inventive, describing in particular the innovative aspects of the envisaged results. Discuss in detail the results (or partial results) that you aim to achieve, such as specific knowledge, the solution to particular problems and academic breakthroughs.}

The core research question that motivates my project is: can a citizen-centric PGS data storage framework, developed using a decentralized storage technology, offer data sharing infrastructure while maintaining privacy safeguards for sensitive data? 
To address this central question, I will investigate the use of data pods, implemented using Solid protocol, to store PGS data in a decentralized and privacy-oriented ecosystem while addressing technical challenges associated with data policies, representation of PGD data as Linked Data, discoverability through querying, and infrastructure that connects data pods to existing clinical workflows and tools. 
My hypothesis is that such a framework can be developed and would offer unique advantages over the existing state-of-the-art institution-centric PGS data storage solutions. 
The following objectives will be undertaken to test my hyposthesis through the production and testing of such a PGS data storage and sharing framework for clinical practice.

(1) \textbf{Identify the workflows, tools, and data networks that utilize PGS data for framework connection.}
_What: Establish the current state-of-the-art in the field of clinical PGS data formatting, usage, and sharing. 
Describe existing methods used for PGS storage, PGS data sharing, and PGS data integration into clinical workflows.
_Result: Establish tangible goals for how my framework can be implemented into existing workflows and initiatives. These goals will inform the architecture of the framework and how future implementations are deployed. 
_Challenging: There are many initiatives, standards, and potenital clinical workflow applications that have different data formatting standards, technical requirements, and implementation specifications. 
_Why me: My education in bioinformatics, past research in genomics, and work experience in clinical settings has provided me with the tools and skills necessary to parse the many options and select those that will offer high impact and fit most seamlessly with the proposed framework.


(2) \textbf{Solid Pod PGS Data Storage.}
_What: Develop methods and a workflow for the creation and hosting of individual patient Solid pods as well as the transfer of PGS data, primarily in vcf file format, into those Solid data pods. 
_Result: The result will offer a proof-of-concept demo that exhibits the Solid decentralized data storage ecosystem can be implemented and host PGS data in a citizen-centric architecture.
_Challenging: Such a framework for genome data has not been undertaken before in the literature and most past implementations of Solid data pod use cases have not been designed to handle the large data files that are present with PGS data. 


(3) \textbf{Data formatting and interoperability.} 
_What: I will experiment with the conversion of PGS data from vcf files to RDF serialized in ttl file format. 
We intend to investigate the viability of representing VCF file data as Linked Data which necesssitates the mapping from this biological file format, vcf, to RDF will first be addressed. 
_Result: I aim to make such a mapping process bi-directional because most existing clinical workflows necessitate input files in vcf format, thereby making reverse compatability important. 
I also aim to make stored PGS data representable using format standards of widely used initiatives such as HL7 FHIR and ... . 
_Challenging: The conversion between vcf and rdf will require the use of an ontology and computation. 
I will assess the computational demands of such a process ... 


\rt{If I understand correctly, you want to look into user interface design? Are you sure you want to get into that? Because then you need to prove you have the qualifications for it, and understand the research problems surrounding UI/UX. Maybe we want to avoid that.}
\ec{Response: Not quite, it is not the user interface I am referring to here, instead the data formatting conversions that are required to connect the PGS data to existing and future tools / pipelines...}

(4) \textbf{Data policy and accessing.} 
_What: A fundamental goal of any PGS data storage system is mainting the privacy of that data. 
I will investigate the ways in which data access requests, data usage consent, and granularization of consent to particular pieces of data can be applied to PGS data using Solid sprecifications.
_Result: I will illustrate the ways in which data can be accessed by authorized users, restrictions for access can be changed, authorization for access can be requested by clinical professionals, and ... (granularization something here)
_Challenging: The trade-off between privacy and accessibility is ----- ??
[...]

(5) \textbf{Data querying}
_What: Investigate query processing techniques for handling the large scale of PGS data stored within and across Solid pods. 
_Result: Assess the efficacy of existing querying algorithms applied to PGS data in both RDF and vcf formats and compare results to common vcf parsing tools publicly available.
_Challenging: vcf files are 100-1000s MBs in size, thus, performant querying can present a challenge.

[Using an existing query engine implementation, such as Comunica, experiment with performing and optimizing basic SPARQL queries on PGS data stored in a Solid pod.]
\rt{What are the problems you want to solve here? What is lacking in existing query algos that necessitate you to build new ones?}
\ec{I have no idea... I have only been told that this will be a probelm that will require solving... I dont know how or in what ways solving it could be achieved...}

Together, these objectives are to be combined into an operational framework that instantiates workflows necessary for setting up and using the system. 
Additionally, advantages, disadvantages, and .... compared to the current state-of-the-art will be presented for future implementations to draw from for future innovation.






\section{3. Research methodology and work plan}
\textit{Elaborate the different envisaged steps (experiments/activities) in your research, and motivate strategic choices in view of reaching the objectives. Describe the set-up and cohesion of the work packages including intermediate goals (milestones).
Show where the proposed methodology (research approach) is according to the state of the art and where it is novel. Discuss risks that might endanger reaching project objectives and the contingency plans to be put in place should this risk occur.
Use a table or graphic representation of the planned course of activities (timing work packages, milestones, critical path) over the 4-years grant period.}

The workflow will proceed in a relatively linear fashion. 
The first tasks will be the assessment of if Solid technology can accommodate efficient and effective genome storage. 
Simultaneously, benchmark VCF genome data will be produced to be representative of real-world VCF data for experimentation in later steps of framework development. 
The project will then require the definition of a genomic ontology language that will be published and made publicly available. 
Once a VCF ontology is established, then VCF to resource description framework (RDF) format conversion and Solid pod data ingestion will begin being experimented with. 
During data ingestion established data formatting standards will be integrated to allow for greater data availability for software development and scalability of this framework. 
Following data ingestion, query algorithms will be tested, adjusted, and created. Iterative development is likely for data ingestion methods and querying approaches due to size and complexity of VCF genomic data. 
Querying is planned to be possible over a single Solid pod (one VCF file) as well as over multiple Solid pods (>1 VCF files), thus iterative querying methods will also be developed. 

[remake project overview figure]
[figure 1 description]
\textbf{Figure 1 PENGQUIN project workflow.} 
White circles represent locations within the workflow where objectives will be achieved. 
For each of the steps in the workflow, the work packages affecting this step are also shown in parentheses (if applicable). 
This workflow is slightly oversimplified for ease of understanding the project.

Identify the workflows, tools, and data networks that utilize PGS data for framework connection.
\textbf{Work Package 1: Establishing the practical connection goals that encourage clinical use}

- Scoping review (storage / sharing approaches that exist)
- File types (WGS and clinically relevant file types)
- Practical use cases (what types of input data do they require / how are results reported)
- What technological foundations will be necessary?

I will conduct a literature review of: the Solid decentralized data storage framework, secure/confidential data storage in decentralized environments, existing human genome single nucleotide polymorphism summary file (.vcf files) parsing approaches, methods of ingesting non-rdf data into rdf data for storage in Solid pods, the establishment of an ontology that can handle such ingestion of genomic data, rdf and non-rdf data fragmentation and fragment organization strategies, link-traversal-based query processing paradigm, and associated linked-data querying algorithms. 
Along with these subjects, the candidate will also investigate strategies pertaining to improving performance of query algorithms using pre-computed summaries and/or linked data short-cut summaries. 
This will be coupled with the representation of genomic data as Linked Data, which will either be materialized beforehand or will be mapped on-the-fly at query-time via a virtualization approach.

While performing this literature study, I will compose a scoping review paper on the field of genome storage that assesses the sharing capabilities that could be leveraged in a clinical setting of existing genome storage approaches and emerging technologies. 

The final work package be applicable to all other work packages to make the suggested work relevant in real life practice as well as allow the current project to be both improved by and applied to other applications in the future.

To avoid privacy issues and improve the communicability of sensitive medical data findings, the Observational Medical Observations Partnership (OMOP)[c] initiative has established methods and data sharing standards that allow for the distribution of medical data findings without the fear of infringing on the privacy of sensitive medical data. 
Within the OMOP initiative, the genomic common data model (G-CDM)[c] has been proposed as a method of improving the circulation and discoverability of genomic research results for researchers. 
Similarly, the HL7 FHIR Genomics Implementation initiative[c] attempts to solve similar issues with genomic data sharing and discoverability without infringing on medical data privacy through the establishment of a modular data ontology. 
These, along with other data standard organizations such as ISO[c] or consortia such as GA4GH[c] are all viable considerations for data representation formats. 
We aim to integrate these data structures and discoverability standards into our PENGQUIN project architecture to encourage improved data and result sharing among the greater research and clinical community. 

An overarching aim for this project is to help drive improvement and accessibility of personalized healthcare through improved PGS privacy and storage and querying efficiency. 
These aims align well with the international Beacon initiative[c,c] to increase the availability and ease of access of genomic data for researchers globally. 
Thus, we aim to make the PENGQUIN Solid pod VCF data storage endpoints beacon resources that can be discoverable via the Beacon API.

Importantly, this option to contribute personal genomic data to the greater Beacon data network, thereby making it discoverable to researchers, will be controllable on an individual basis as an opt-in option. 
Another advantage of the Solid ecosystem in this context is the ability of any individual to change their beacon sharing preference from their personal Solid pod at any point in time. 
Increasing the amount of genomic data available to researchers will help contribute to the further progression of personalized healthcare efficacy for larger, and more diverse populations of people, aligning closely with our goals for this Ph.D. project.

\textbf{Tasks:} 
\begin{enumerate}
	\item Literature review of existing genome storage implementations
	\item Scoping review paper composition
	\item Submission for paper publication in a peer-reviewed journal
\end{enumerate}

\textbf{Risks and Mitigation:}  
\begin{itemize}
	\item \textbf{Paper is not accepted:} ... 
	\item \textbf{A different group publishes a highly similar paper first:} ...
\end{itemize}

\textbf{Work Package 2: Storing and publishing personal genomic data in a decentralized environment} 

- Set up solid pods using the CSS
- Create an interface for data management and uploading
- Make a test dataset of PGS data for future experimentation

In this work package, I will set up the foundations for experimentation in later work packages. 
A test dataset will be constructed using publicly available Illumina platinum genome files[c]. 
These files will be used to provide benchmark PGS data files for early stage testing the storage, policy, and data formatting approaches within a single Solid data pod and across multiple Solid data pods later. 
Also, this benchmark data will offer a set of realistic query workload data that is representative of real-world genomic data thereby, offering useful feedback during framework development. 
This test data may be augmented with other publicly available data and/or AI generated PGS data later in the project when the number of PGS offered by the Illumina sequences are insufficient for testing framework scalability.

Within this work package, I will also create server-hosted Solid pods that are representative of individual patient Solid pods using the Community Solid Server (CSS) specifications. 
We will then upload PGS data from the test dataset into these patient data pods. 

\textbf{Tasks:}  
\begin{enumerate}
	\item A test dataset is assembled consisting of publicly available data
	\item Solid pod(s) is created using the CSS specifications
	\item A user interface for PGS data uploading to the pod is developed
	\item Integrate user controls for privacy and discoverability of data within the pod
\end{enumerate}

\textbf{Risks and Mitigation:} 
\begin{itemize}
	\item \textbf{Existing genomic data ontology descriptions are insufficient for conversion to RDF:} ...
	\item \textbf{Software Dependencies:} Various software will be used for this project. Generally, software is known to exhibit issues concerning quality, versioning, and documentation. If such problems are encountered troubleshooting will include utilizing other, comparable software to accomplish the task or contacting the producer of said software for troubleshooting.
	\item \textbf{The Solid protocol is insufficient for envisioned development:} ...
\end{itemize}

\textbf{Work Package 3:  Storing PGS data as RDF}

- choose an ontology for the conversion of VCF formatted PGS data to RDF
- benchmark the computational costs of this conversion
- develop strategies to efficiently convert between these two formats
- begin experimentation with linking *other* (what kinds??) patient data to PGS data


PGS data interoperability for various applications, tools, and user interfaces is important if such a framework is to be scalable. 
One route to achieving this interoperability along with other potential advantages is to convert PGS data into RDF. For this, there is a need for a bidirectional mapping process, that allows PGS data to be converted into RDF, and the other way around. 
This mapping process could either happen as a pre-processing step during the ingestion of data into Solid data pods (materialization), or during the retrieval process if genomic data will be stored in their raw non-RDF representation in Solid data pods (virtualization).
After these file uploads, investigation into how PGS data can be translated into RDF format[c] according to the Linked Data principles[c]. 
Preliminarily, we will focus on the conversion of VCF files to RDF representations serialized in turtle (ttl) format. 
For this conversion, we will use ontologies available from projects such as SPHN RDF or HL7 FHIR. 
Additionally, there is promise in representing genomic data as a graph as is reflected in recent advances in reference pangenome representations[c]. 
In this project, we foresee great potential in the representation of PGS data in RDF, thus allowing for the linking of other useful data such as pharmacogenomic findings, rare disease markers, or other clinically relevant data to be linked to certain parts of the patient\textquotesingle s genome after discovery. 
Furthermore, the investigation of genomic data format conversion as a mapping process while comparing the impact of materialization and virtualization in terms of ingestion speed, storage size, and query performance will be assessed. 
More specifically, since data inside Solid data pods can be represented in a variety of different views, such as documents, the Ph.D. candidate will investigate different fragmentation strategies for publishing genomic data represented in RDF. 
These fragmentation strategies will be compared in terms of storage size, query performance, and privacy-compliance.

\textbf{Tasks:} 
\begin{enumerate}
	\item Creation of data format conversion methods (first from VCF to RDF)
	\item Integration of format conversion methods to an API for application connection?
	\item Web application that allows for viewing of PGS data contained within a pod
\end{enumerate}

\textbf{Risks and Mitigation:} 
\begin{itemize}
	\item \textbf{Evolving PGS Technological Advances:} 
	Long read sequencing has been decreasing in price in recent years and offers many advantages over the currently most common form of short-read shotgun genome sequencing. 
	With a widespread transition to long read sequencing, the way downstream genomic files, such as VCF files, are created and formatted may change. 
	It is unlikely that such a drastic change will take place during this Ph.D. project, but if such a breakthrough occurs, the Ph.D. candidate and advisors will assess altering the input genomic files to align with the project\textquotesingle s goal of creating a framework useful for advancing personalized healthcare.
	\item \textbf{Software Dependencies:} Various software will be used for this project. Generally, software is known to exhibit issues concerning quality, versioning, and documentation. 
	If such problems are encountered troubleshooting will include utilizing other, comparable software to accomplish the task or contacting the producer of said software for troubleshooting.
\end{itemize}


\textbf{Work Package 4: The policies for preserving PGS data privacy}

- establish a methodology for requesting consent from a pod owner to access data (are there frameworks for this already?
	-- Will have a notification and some sort of view restriction update component
- Make a method for pod owner to change permissions after intial permission
- Develop a system where elevated status is give to certain users (hospital admin / physician)

\textbf{Tasks:} 
\begin{enumerate}
	\item Create mapping scripts that present data in requested format (start with VCF and HL7 FHIR)
	\item Depending on use cases create additional mapping scripts for format alterations
\end{enumerate}

\textbf{Risks and Mitigation:} 
\begin{itemize}
	\item \textbf{Evolving Format Standards:} An advantage of the proposed system of creating modular mapping scripts that allow for the translation of PGS data from RDF to any requested format. 
\end{itemize}


\textbf{Work Package 5: Querying over PGS data in one and many pods}

- how is data discovered in a pod?
- benchmarking with different linked data fragment traversal algorithms
- experimentation with client vs server computation for query performance
- compare performance to existing VCF parsing algorithms

This work package will build upon the storage of personal genomic data in Solid data pods from the previous work packages. 
I aim to enable queries to be executed across PGS data that are contained within a single data pod or are spread over multiple data pods. 
These data will be represented as a collection of nodes that are interlinked directly or indirectly in a knowledge graph contained within the user\textquotesingle s personal Solid data pod. 
A major challenge presented by this approach is that there is a need for efficient query processing algorithms that can handle large scale decentralization. 
Concretely, we will build upon the link traversal query processing (LTQP) paradigm, which has been shown to be an effective method for querying within a decentralized environment such as Solid[c]. 
However, LTQP is known to currently perform sub-optimally for larger dataset sizes and complex queries, which are properties present in the PGS data space. 
As such, there is a need for new LTQP algorithms that can achieve the required levels of performance in terms of query execution time. 
Concretely, the Ph.D. candidate will assess and improve LTQP algorithms that will exploit intrinsic properties of genomic data that can help speed up query performance. 
Furthermore, the impact of pre-generated summaries[c] will be investigated when introducing them to the decentralized environment. 
The working approach will then be applied to a population of PGS data in which new strategies of organizing computational architecture and utilizing metadata between genomes will be investigated to optimize storage size and query performance when querying more than one personal genome.

\textbf{Tasks:} 
\begin{enumerate}
	\item Establish that PGS data within a Solid pod can be queried using SPARQL
	\item Assess existing LTQP algorithms using an engine such as Comunica and assess performance on genomic data via benchmarking
	\item Optimize basic query functionality to levels acceptable for clinical practice
	\item Integrate query functionality into a user interface (with example queries for non-experts)
\end{enumerate}

\textbf{Risks and Mitigation:} 
\begin{itemize}
	\item \textbf{Computational Load:} Various software packages will be used for brute force SAP detection. 
	Both VITO and UGhent have access to the Flemish Supercomputing Centre for grid computing in case the Ph.D. lacks computational resources. 
	\item \textbf{Dataset size:} If personal genome datasets are too large to store in a decentralized manner with acceptable query performance. 
	If this occurs, a shift towards more centralization will be investigated in the form of summaries[c], and more expressive query interfaces will be added to Solid data vaults[c]. 
	The range of pods over which summaries and query interfaces are defined will be configurable, which means that the trade-off between centralization and decentralization can be tuned.
\end{itemize}


\textbf{Work Package 6: Component consolidation and framework publishing}

- combine all the parts into a single framework with usage guidelines and documentation (possibly an MIT license?)



\textbf{Planning:}
My project consists of 5 work packages denoted as “WP”. 
This will be bundled into a Ph.D. dissertation for a final thesis defense. Figure 2 shows a Gantt-chart of the Ph.D. project on a quarterly basis.  
Each work package is split up into different tasks with a dedicated amount of time allocated to it. 
This will allow for a good time and project management. 

[Figure 2: Insert gantt chart here]
[Figure 2 description]
\textbf{Figure 2 Gantt chart of the Ph.D. project timeline on a quarterly basis.} T denotes different tasks of a work package. M denotes different milestones, such as finishing and submitting a manuscript to a journal. 
Green denotes working on the thesis dissertation and defense. 
This is allocated as the final 6-9 months of the Ph.D. project to make all preparations for the defense. 


\section{4. Strategic dimension and application potential}
\textit{Elaborate the strategic dimension of your research, with regard to the (long-term) potential for innovative applications. 
Substantiate the PhD project’s strategic focus on economically relevant innovations. Justify how the chosen research approach (if successful) is the appropriate one to achieve the anticipated application(s) (potentially long term).
Elaborate the strategic importance of the potential applications to possible users (impact). Show how (if the project is successful) new products, services and/or processes may affect business of specific companies, a collective of companies and/or a sector and/or may be closely aligned with the Flemish science, technology and innovation transition priorities  (Flanders in transition. Priorities in Science, Technology and Innovation towards 2025) (socio-economic benefits). Societal impact should always be linked to a (in)direct (macro)economic benefit, e.g. cost reductions in health care, higher education level, environmental impact etc. should be positioned in an economic context.}

The infrastructure for sharing data between healthcare institutions is rapidly expanding but running into significant challenges such as lack of data interoperability, privacy and consent issues, as well as legal and regulatory restrictions. 
With the emergence of patient genomic data as a tool for clinicians, establishing the infrastructure for patient genomic data sharing is an economic niche that is largely unfilled. 
There certainly exists a fledgling private genomic service industry dominated by companies such as 23andMe, Ancestry.com, sequencing.com, and others establishing that genomics data generation and storage holds importance to consumers for various personal and medical reasons. 
At the same time, hospital systems exclusively store and maintain all patient PGS data that is used for clinical applications. 
There is notable nuance between these two sectors including different forms of genomic data being generated, stored, and used, differing legal oversight concerning commercial genomic data and health data, and formatting differences between the genomic data stored. 
Regardless, in our modern age of big data, data duplication due to data siloing, energy waste due to computational demands during data regeneration, and intrinsic security concerns for modern data storage techniques are major economic inefficiencies of the current system. 

A hypothetical company that, in coordination with policy makers and regulatory bodies, creates a scalable storage and data sharing infrastructure for genomic data, which could also grow to include all patient health data in time, stands to greatly increase the efficiency of PGS data usage in healthcare. 
Such efficiency increases could help lower patient costs for specialized genetic tests, remove data management and administration from hospitals, thereby reducing costs, and establish a new market within which economic growth could result. 

My project presented above is designed to present a proof-of-concept framework, both providing and demonstrating the technological foundations for the storage of PGS data in Solid pods, the controlling of access to that data on a granular level, the ability for that data to be queried, and exhibiting the accessibility of the stored PGS data to users, web applications, and medical tools in formats that can be used by both those currently in use and applications developed in the future. 
Such a framework will provide the outline of necessary implementation considerations from a technological perspective while also highlighting strengths and weaknesses of such a system that may be influential in attempts at scaling such an infrastructure. My project is also being undertaken parallelly with the Digital Twins of citizens/patients initiative that is happening at VITO in conjunction with the Flemish government and (?) for evolving the way medical data is stored to be increasingly citizen/patient centric. 
This initiative along with the WE ARE project at VITO are both exploring the ways in which decentralized storage could be applied to sensitive data to improve the way that consent is given and requested for such data. 

Notably, the framework I am developing is intended to augment and contribute to advances in medical patient care by removing existing cost and architectural barriers to using PGS data more broadly in clinical practice. 
In the short-term, the project is being developed to be integrated into ongoing research and product development at VITO Digital Precision Health. 
Products aimed at improving the way drug prescription is practiced by using a genetic screening tool that leverages documented genetic predispositions to drug ineffectiveness are currently being developed to be connected to my framework of Solid pod stored PGS data. 
Additionally, connection to other known and well-used workflows such as for NIPT and rare genetic disease screening is a primary goal for my project. 
Genomic data interoperability is of utmost importance for clinical application and is therefore a cornerstone of my project. 

Lastly, public perception is a crucial element to the economic growth of a product or sector. With personal data usage transparency as well as greater calls for digital data privacy protections becoming more important to the public, such considerations should also be priorities to how health data is managed. 
The existing system of genomic data storage for use in healthcare is prone to data leaks and heavily restricted patient transparency due to the central architecture of institution-centric data stores. 
With my proposed framework, patients would be more intimately connected to their data, potentially even having a say over to whom and what their data is visible. 
Such improved transparency, when paired with decreased risk of large-scale data leaks, is likely to be well-received by the general public. 
Such public support could help drive such a framework adoption to a larger scale such as nationally or even to be the standard for a system like the EU. 
This large scale goal, while nowhere near attainable in the near future, would present the greatest possible outcome for such a project and exhibit a somewhat unintuitive increase in greater genomic data privacy and shareability. 
In this scenario, there is also room for healthy competition within such a niche as various pod providers could offer hospital systems and educational institutions different rates for data storage and associated computation.

*** Disruptive Innovation --> Economic added value ***
	--Especially specifically for Flanders–

\bibliography{poster_proposal}
\end{document}