% Compile with XeTeX, e.g. latexmk -xelatex -shell-escape -pvc -pdf report.tex
% Template based on Ruben Verborgh's FWO template.
\documentclass[a4paper,11pt]{article}

% Page setup
\usepackage[a4paper,margin=3cm,right=2.5cm]{geometry}
\usepackage{changepage}

% Typography
\usepackage{fontspec}
\setmainfont{Calibri}
\usepackage{microtype}
\usepackage{csquotes}
% Paragraphs
% Sections
\usepackage[noindentafter]{titlesec}
\titleformat\section{\bfseries}{}{0em}{}
\titlespacing\section{0em}{1em}{0em}
\titleformat\subsection{\fontsize{13pt}{13pt}\selectfont\bfseries}{}{0em}{}
\titlespacing\subsection{0em}{1em}{.5em}
\titleformat\subsubsection{\color{black!65}\bfseries}{}{0em}{}
\titlespacing\subsubsection{0em}{0.66em}{0.13em}
\titleformat\paragraph[runin]{\bfseries\itshape\color{black!60}}{}{0em}{}
\titlespacing\paragraph{0em}{.5em}{.66em}
% Lists
\usepackage[inline]{enumitem}
\setlist{nosep}
% Varia
\newcommand\expl[1]{\textcolor{black!50}{\emph{#1}}}
\usepackage{comment}

% References
\usepackage[hidelinks]{hyperref}
\usepackage[capitalize,nameinlink,noabbrev]{cleveref}
\let\UrlFont\itshape
\usepackage[
  backend=biber,
  bibstyle=trad-plain, % Was trad-abbrv, but that does not compile
  abbreviate=false,
  doi=false,
  isbn=false,
  giveninits=true,
  sorting=none,
  sortcites=true,
  citestyle=numeric-comp,
]{biblatex}
\renewcommand\multicitedelim{\addcomma}
% Custom author list length
\addbibresource{EDC_references.bib}
\renewcommand*\bibfont{\fontsize{10pt}{13pt}\selectfont}
\bibitemsep 1pt plus 1pt minus 1pt
% Slanted "et al."
\usepackage{xpatch}
\xpatchbibmacro{name:andothers}{%
  \bibstring{andothers}%
}{%
  \bibstring[\textsl]{andothers}%
}{}{}
% Underline my name
\usepackage[normalem]{ulem}
\def\firstname{Elias}
\def\lastname{Crum}
\renewcommand\mkbibnamegiven[1]{%
  \ifboolexpr{test {\ifdefequal\firstname\namepartgiven} and
              test {\ifdefequal\lastname\namepartfamily}}
  {\uline{\namepartgiveni~\namepartfamily}}
  {\namepartgiveni~\namepartfamily}%
}
\renewcommand\mkbibnamefamily[1]{}

% \strong
\makeatletter
\ifdefined\strong
\renewcommand{\strong}[1]{\@strong{#1}}
\else
\newcommand{\strong}[1]{\@strong{#1}}
\fi
\newcommand{\@@strong}[1]{\textbf{\let\@strong\@@@strong#1}}
\newcommand{\@@@strong}[1]{\textnormal{\let\@strong\@@strong#1}}
\let\@strong\@@strong
\makeatother
% Set contributions apart from other bolding
\newcommand{\contribution}[1]{\strong{\textcolor{RoyalBlue}{#1}}} % but a less ugly color?

% Reviewing
% \input{reviewing}

% Graphics
\usepackage[framemethod=TikZ]{mdframed}
\usepackage{pgfgantt}

% Misc
\hyphenation{LTBQP IBQP}

\begin{document}

\begin{mdframed}[backgroundcolor=black!17,linecolor=black!0,font=\bfseries]
	\centering
	PHD FELLOWSHIP STRATEGIC BASIC RESEARCH\\
	PROJECT OUTLINE (MAX. 12 A4 pages)\\
	\end{mdframed}
	\vspace{-.5\baselineskip}
\title{PHD FELLOWSHIP STRATEGIC BASIC RESEARCH PROJECT OUTLINE}

\begin{refsection}

\section{Rationale and positioning with regard to the state-of-the-art}
% Elaborate the scientific motivation for the project proposal based on scientific knowledge gaps, and the issues and/or problems that you want to solve with this project. Concisely describe the related international state of the art, with reference to scientific literature. Position your project in relation to ongoing national and international research.
% --- aim for 2 pages ---

\smallskip

\paragraph{Decentralized Landscape}
% decentralization to combat centralization (include examples?)
Data decentralization initiatives~\cite{solid, mastodon, decentralizednanopubs} are working to reduce the data siloing caused by data centralization on the Web.
A leading decentralized storage strategy is the use of personal data vaults.
The Solid protocol in particular offers user-moderated access controls, data linking in and across vaults using the Resource Description Framework~\cite{spec:rdf}, represented as triples with universal semantics, built on Linked Data principles~\cite{linkeddata}, and information extraction via querying using the SPARQL query language~\cite{spec:sparqllang}.

% something about remaining challenges related to implementation and computation not being a part of the storage infrastrcture



\paragraph{Personal Genome Sequencing in Healthcare}
% why could genome sequencing benefit from decentralization
% current centralization limits scalability --> due to costs
% costs are high because PGS data  is big, expensive to generate, and requires a lot of maintenance oversight
% cost decreasing measures (sharing/data linking/interoperability?) are hard due to privacy constraints (PGS data is sensitive)
% centralized database technologies pit privacy and cost reduction as antagonists...

Around the same time that the World Wide Web was being established, DNA sequencing technologies were just starting to be applied to the human genome~\cite{hood_1987}.
At the time of writing, there are now multiple domains of clinical practice where patient personal genome sequence (PGS) data are now used to inform medical decision making. 
Examples include in drug development \cite{ko_new_2022}, cancer diagnosis and treatment~\cite{mcleod_cancer_2013}, and rare genetic disease identification and treatment~\cite{souche_recommendations_2022}.
How this integration is deployed varies by clinical domain, but improved outcomes have generally been observed~\cite{mathur_personalized_2017}.
Despite great promise presented by various use cases, barriers to widespread adoption remain~\cite{stefanicka-wojtas_barriers_2023}.

One major barrier to scalability is presented by the costs of data generation and storage~\cite{genomics_cost_2023}.
The average human genome is slightly over 3 billion base pairs in length and during a whole genome sequencing workflow, various sequence formats that offer different sets of information are produced~\cite{bagger_whole_2024}.
Of these, Variant Call Format (VCF) files~\cite{danecek_variant_2011} serve as the state-of-the-art for most clinical genomic applications and are typically between 100-1000s MBs within computer memory. 
Beyond just the costs of first time generation and storage, it is not uncommon for regenerating results and sequences if a patient moves to a different healthcare institution~\cite{that one citiation}.

The costs of producing and maintaining these data are further increased by the privacy protections needed for PGS data~\cite{GDPR_2016}.
With the enlarged threat of hacking, phishing, and login credential compromisation that is only increasing~\cite{noauthor_ransomware_nodate}, hospitals and health care institutions have taken steps to enact tighter restrictions on data access and increase their cyber security budget to handle security threats and audits.


\paragraph{PGS data sharing in academic research}
Because hospital systems have a wealth of clinically relevant data, but that data is largely inaccessible outside of those institutions, research motivated initiatives working to increase the accessibility of that data have gained traction recently~\cite{data_sharing_2019}.
Practically, this has led to the development of infrastructure that allows for sharing of genome data between institutions, creating federated centralized databases. 
Among the largest and most prevalent in Europe is GA4GH Beacons~\cite{rambla_beacon_2022}. 
Despite this step towards increased sharing and cost reduction, advancements in state-of-the-art infrastructure and standards are not directly translatable to clinical practice. 


\paragraph{Decentralized PGS data storage}
A possible solution to the challenges faced is through reorganization of how data is stored and discovered. 
The citizen-centric model places the patient at the center, and is not an entirely novel concept~\cite{brands_patient-centered_2022}.
Within the current system, a citizen-centric model is difficult to implement due to technological challenges presented by centralized databases.
The Solid protocol~\cite{solid}, a decentralized data storage approach, is composed of specifications more conducive to construction of a citizen-centrica data storage strategy for clinical data.
Specifically, Solid offers the ability to granularize data privacy, allow authorized data access over the web, and represent stored data as Linked Data, all features that can work to remove some of the antagonism between cost reduction and privacy preservation.
In recent years, there have been initiatives for representing biological data as RDF \cite{sib_rdf_2024}, specifically extending into clinical biology recently~\cite{sphn_rdf_2023}. 
While there is little research into the benefits of representing genomics data as RDF, past experiments have shown that linked data integration into clinical practice results in improved outcomes~\cite{farinelli_linked_2015}.

% ^ Can you hint towards some research problems related to it, and mention it in bold? (in general, placing some stuff in bold will improve readability for people that will just skim your proposal).

Furthermore, using Solid pods for data storage also makes it possible for non-linked data stored in the pod, such as test result files, to be linked to RDF data, improving data connectivity.
As of yet, decentralized storage technologies have not meaningfully expanded to use in clinical practice.
If they did, things like data sharing, reduced data duplication, and increased data privacy controls could contribute to the PGS cost reductions and improved scalability.
Adaptation of Solid decentralized technology to clinical genomics does not come without challenges.
Large genomic data, the fact it any technology needs to connect to both old and new application/tools, and the lack of existing infrastructure for implementation are noted challenges. %check this later 
At the same time, these challenges also offer an unstudied frontier of decentalized web technology where technological progress could provide significant impact. %same here

\paragraph{Link Traversal Query Processing (LTQP)} %address this when your brain is working
To make sense of linked genomic and clinical data, approaches to parsing and querying that data must also be investigated, especially to encourage greater data discoverability and usage in clinical practice.
Recent work has established that the querying of Linked Data in decentralized environments is possible~\cite{taelman_LTQP_2023}, but these results were obtained with assumptions different than those presented by patient genome pods.
Here, querying will be performed over a potentially large number of data pods containing large amounts of linked data, a situation not extensively investigated. In this context, it is likely that existing LTQP algorithms and approaches will require innovation. 

It is documented how many personal data vaults of small amounts of data can be queried, but little has been done to investigate how many data vaults of large amounts of relatively similar data could be queried.

At present, the current state-of-the-art methods for data storage are centralized in nature, following an institution-centric model. 
This data storage strategy has posed great challenges to the scaling of personalized medicine, the use of patient genomic information to inform clinical decision-making.


\paragraph{Project Motivation}
Despite there being no real solutions to the current antagonism between privacy and cost reduction for PGS data usage in healthcare, there is also a conspicuous gap in the current scientific discourse around the development and implementation of a proposed solution. 
This gap underscores the necessity of my Ph.D.
\textbf{I aim to improve the connectedness and shareability of genomic data storage(s), while preserving data privacy, through the 
% make this more concrete
integration of various domains of semantic web research into a novel, holistic framework designed for use in clinical practice.}
My Ph.D. will also aim to demonstrate the limitations of current state-of-the-art semantic web technologies in this novel application domain with the intention of driving innovation and discovering future research pursuits.



\section{Scientific research objective(s)}
% --- aim for 1 page ---

\begin{comment}
Describe explicitly the scientific objective(s) and the research hypothesis. 
Explain whether and how the research is specifically challenging and inventive, describing in particular the innovative aspects of the envisaged results. 
Discuss in detail the results (or partial results) that you aim to achieve, such as specific knowledge, the solution to particular problems and academic breakthroughs.
\end{comment}
\smallskip

\noindent
My proposed research endeavors to fuse cutting edge semantic web technologies with decentralization technologies into a novel proof-of-concept PGS data storage and sharing framework for use in clinical practice. 
To realize such a framework, I will apply the technologies of five distinct areas of active research to a data ecosystem to which they have not been designed for.
This ambition frames the central research question I aim to answer: \textbf{Can combining the Solid specifications for data storage with other compatable cutting edge innovations for data policy, linking, and querying be instantiated and deployed as a framework that provides clear advantages over the existing PGS data storage protocols in health care?}

The core research question can be decomposed into four specific research questions.
First, can the decentralized storage protocol Solid, with which there have been few published implementations of large data storage, % is this accurate?
and no published implementations of clinical genomic data storage, offer suitable storage infrastructure for this novel data? 
I hypothesize that the Solid protocol will be able to store clinical genomic data storage.
Further, to offer usage advantages over existing systems, can the representation of PGS data using RDF as Linked Data be accomplished? 
A further aim within this objective is exploring if storage of PGS data as RDF using Header Dictionary Triples (HDT) format~\cite{spec:hdt} provides similar levels of usability of genomic data with significantly decreased storage costs.
With the motivation of optimizing efficiency, I will also investigate the use of a bi-directional mapping index for the conversion between VCF and RDF.
For these aims, my background in genomics will be valuable, specifically when optimizing indexing and format conversion, because of my knowledge of genomic file anatomies and how data is semantically represented in genomics file formats.

Second, because of the sensitive nature of PGS data, do the specifications provided by Solid provide for enough flexible control of the privacy of PGS data while also allowing for increased authorized sharability?
I aim to demonstrate possible configurations of Solid data vault privacy policies as well as offer a functionality within a web application for the alteration of these policies but authorized users.
Additional investigation into how pre-computed privacy-preserving summaries of data vault contents outside of a patient data vault in an aggregator can be generated will be attempted using presviously descibed theoretical methods~\cite{taelman_privacyAgg_2020}.
Within this component, I will also attempt to connect experimental patient data vaults to the Beacon federated network~\cite{rambla_beacon_2022}.
Querying capabilites of the beacon will be assessed in a later work package.
I am uniquely situated for assessing these privacy policies because of my past experience working in a clinical setting alongside physicians as well as my understanding of different sets of US and EU regulations mediating data privacy requirements.

Third, for the stored genomic data and linkages to be usable in clinical practice, a querying method is necessary.
In a citizen-centric clinical data storage implementation, there are potentially thousands of heterogeneous, large sources to be queried over.
It is an established challenge for federated decentralized querying in such environments, % know of any good citations for this?
informing the question: can querying over these sources be achieved through the use of Link Traversal Query Processing algorithms that are modified to utilize pre-computed or on-the-fly generated indexes?

% need either higher level OR more info about LTQP + indexes comes out of no where -- probably need some more background on that in state of the art...

I have experience with index guided genomic data parsing that will help guide developing and optimizing query algorithms that can efficiently handle the large data presented by genomic data. 

Together, these components will be combined into an operational framework in the fourth component. 
The driving question being, can these three different groups of features be combined into a cohesive web application and deployed together?
The framework, once produced, will be compared to existing strategies for storing and sharing PGS data to assess the efficacy of transitioning toward product production and specific clinical use case adaptation.
The proposed scientific approach also aims to test the application of numerous fields of semantic web research to a clinical knowledge domain. 
In the process, providing insight into how many large data vaults informs future areas of innovation in decentralized web research.

\newpage

\section{3. Research methodology and work plan}
% --- aim for 4 pages (WP1: 1; WP2: 1,5; WP3: 1,5) ---

\begin{comment}
\textit{Elaborate the different envisaged steps (experiments/activities) in your research, and motivate strategic choices in view of reaching the objectives. Describe the set-up and cohesion of the work packages including intermediate goals (milestones).
Show where the proposed methodology (research approach) is according to the state of the art and where it is novel. Discuss risks that might endanger reaching project objectives and the contingency plans to be put in place should this risk occur.
Use a table or graphic representation of the planned course of activities (timing work packages, milestones, critical path) over the 4-years grant period.}
\end{comment}

\medskip

\noindent
My research plan consists of three component objectives, representative of three core functionalities of my proposed framework.
%
First, I focus on the foundational infrastructure for data storage and formatting for the framework.
%
Second, I focus on framework data privacy policies for granular, flexible data policy enforcement.
%
Third, I integrate querying functionality to the data storage framework using a query engine approach and modified LTQP algorithmic approach to allow for data discoverability.
%
After each component, I elaborate on its risks.
Then, I present my work plan.

\newcommand\WPa{Storage and formatting PGS data in a citizen-centric architecture}
\subsection{Component~1: \WPa}

The foundation of my proposed framework is the data storage infrastructure.
To implement a citizen-centric storage of PGS data, a decentralized storage strategy offers a maleable platform.

%maybe put an additional task here for review paper composition??

\newcommand\WPaa{Storing PGS data in Solid data vaults}
\subsubsection{Task~1.1: \WPaa}
% citizen-centered data storage will increase efficiency of use in health care
% this organizational strategy is not possible in centralized databases
% so, we will turn to decentralized approaches
% Solid was chosen because it is not social network specific, is growing in popularity, and has other nice features
% Using my experience working with genomic data, I will try to use solid to efficiently store PGS files
% I will show that PGS data storage is possible, thereby shoing that large data storage in Solid is possible.
% result will be the development of a workflow for creating, hosting, and uploading data into patient solid pods

The decentralized storage technology I chose to use is Solid, because of its growing populatiry[c] and its support of specifications for data sharing over the web and granular provacy controls... %not sure if this is a good argument...

Here, I will test the viability of Solid data pods for patient PGS data storage, thus, testing my hypothesis that Solid can support PGS data storage. 
Using my experience with genomic data types and file representations, I will assemble a test dataset composed of publicly available genome files~\cite{platinum_genomes, others...}. 
These files will be used as representative "patient" PGS data for all future experimentation. 
I will also create server-hosted Solid pods using the Community Solid Server (CSS) implementation of Solid~\cite{css}. 
Each pod will be a storage container for a single individual\textquotesingle s PGS data. 
I will upload a single PGS file, a VCF file, into one "patient\textquotesingle s" pod to test basic functionality of a Solid pod for hosting large genomic data. 
The result of this task will be the \textbf{development and documentation of a workflow for creating, hosting, and uploading PGS data into patient solid pods}.


% evalutation
% bAll tasks within WP1, including test data set assembly, Solid pod creation and hosting using the CSS, and test data uploading to Solid pods will be evaluated only for functionality.

% novelty
% The use of the CSS for Solid pod hosting for research purposes is state-of-the-art, but the there have been no published experiments documenting the use of Solid pods for storing PGS data, which are much larger than in past Solid experimentation. 

\newcommand\WPab{Converting PGS data as Linked Data using RDF}
\subsubsection{Task~1.2: \WPab}

To campitalize on data storage efficiency and future application potential, I will convert PGS data from VCF to RDF allowing for linking of other medically relevant data to patient genomic data within the patient\textquotesingle s pod and outside of it.
This aim will address well documented current challenges in medicial record utilization relating to scatteredness of pertinent clinical information~\cite{...}.
To convert PGS data from VCF to RDF, we will investigate a format translation process using the SPHN RDF ontology~\cite{van_der_horst_bridging_2023}. 
For this translation process, we will experiment with different approaches, such as a bidirectional mapping index, for efficient reversal of conversion to ensure the conversion process can be reversed for connecting to existing clinical workflows that request VCF format inputs. 
Direct conversion between VCF and RDF will be evaluated in terms of computational overhead, conversion time, and memory usage.
The same evaluations will be performed use the generation and use of an intermediate mapping index file. 
These comparisons will be documented in a formal benchmarking study.

Data that is serialized as RDF can be represented in a number of formats in computer memory~\cite{...}.
To minimize the storage costs of large PGS data, I will utilize HDT format to compress the PGS data while retaining the ability to query and index it~\cite{...}.

I then intend to demonstrate the linking of part of a patient\textquotesingle s genome to
(A) other data within the patient\textquotesingle s pod, 
(B) data in a public database outside of a patient\textquotesingle s pod, and
(C) data from another patient\textquotesingle s pod.
%Data linkages will be (how to implement this? Is that necessary to say?)
The power of linking the VCF data to other clinically relevant data will be during querying, which will be performed in Component 3.


% novelty
%Because representation of VCF files in RDF has not been heavily studied, these will be the first experiments of their kind.
%While Linked Data is state-of-the-art, these concepts have not yet been applied to clinical genomic data.
%The power of linking the VCF data to other clinically relevant data will be especially realized when these semantic links are discovered during querying, which will be investigated in WP5. 


\subsubsection{Risks}
The main risk of storing PGS data in Solid data vaults (Task 1.1)
is related to the size of PGS data. 
% I am not sure if this needs to be mentioned... probably not

The main risk of converting PGS data to Linked Data using RDF (Task 1.2)
is that an ontology that semantically represents PGS data is required for this conversion. 
To mitigate this risk, I will only focus on converting VCF data to RDF, which will make use of the publicly available SPHN RDF ontology.
If this ontology is insufficient, I will work with members of our group with experience in ontology definition to create my own ontology for the conversion process which may take some time but will allow for progression to later work packages.


\newcommand\WPb{PGS data privacy policies}
\subsection{Component~2: \WPb}

To effectively store sensitive information, privacy protections are of paramount importance. 

I will experiment with the design and implementation of multiple levels of authorization as well as methods that allow for dynamic control over data discoverability, read/write access, and data access consent requests within a patient\textquotesingle s Solid pod, made possible by the Solid specification[c]. 
I will develop and test three functionalities for privacy modifications.
(1) registration of a pod to an individual patient,
(2) submission of a request to access stored data from a data requester, the notification of the patient, and the consent or denial by the patient, and
(3) permission revoking capabilities as well as an opt-in option to share their data with researchers. 
All of these methods will be integrated into the framework\textquotesingle s web application.
To utilize these methods, various levels of access to pod read and write privileges will be created to fill the needs and roles of participants of a PGS clinical workflow. 
Attaching differing levels of authorization to data will be assessed by creating various profiles that reflect clinical roles and access levels and attempting to access data via user-mediated, application requesting, and querying approaches. 

% novelty
%Assigning the above permissions within Solid is an open area of research and there are currently state-of-the-art protocols implemented in the CSS that allow their implementation.
%The described access schema has not been attempted in the presented level of detail for clinical genomic data.


\subsubsection{Risks}
Privacy is a tricky subject especially in terms of governance

\newcommand\WPc{Querying PGS data over one and many data vaults}
\subsection{Component~3: \WPc}

% Most research done with decentralized federated querying has been on many small pods
The problem space presented by citizen-centric data vaults is novel for federated decentralized environemnt querying. 
Established techniques for federated SPARQL querying over a \emph{small number of large sources} have been documented~\cite{hibiscus, tpf, sparql_adaptive_anapsid}.
Techniques for federated SPARQL querying over decentralized environments with a \emph{large number of small data sources} have also been documented[c].
Personal genomic data vaults for clinical practice present a third querying landscape consisting of a \emph{large number of large data sources}.
One advantage presented by the PGS data stored in the present situation is that the data is formatted in a homogeneous way allowing for summaries to be used for improving query performance[c].
Concretely, I will assess and improve algorithms for query execution guided by PGS data indexes,
and assess the performance of these algorithms compared to current PGS parsing methods...?

\newcommand\WPca{Link Traversal Query Processing algorithm benchmarking}
\subsubsection{Task~3.1: \WPca}

This work package will establish a querying mechanism for data in the patient Solid pods that takes into account patient pod data, user permissions, and data linkages. 
I hypothesize that a querying functionality that utilizes a query engine computational strategy will be able to query over patient Solid pods and return query results.

I will executing queries across PGS data contained in patient pod(s) through the use of the query language SPARQL.
Query execution requires a source for computation which is not currently provided by the Solid pods themselves.
I will investigate the use of a query engine, such as that offered by Comunica~\cite{comunica}, to perform the queries apart from the data stores.

For PGS data querying, I will benchmark and potentially build upon the link traversal query processing (LTQP) paradigm~\cite{taelman_evaluation_2023}, which has been shown to be an effective method for querying within Solid.  


Query engine functionality will be evaluated using query execution time and computational load metrics as well as query results assessment. 
Query results will establish the functionality of data linkages from WP2.

Benchmarking will be done for existing LTQP algorithms and altered query algorithms that utilize genomic index files and results will be compared.
Ideally, success will be determined by queries that return correct results in under 10 minutes for users and potentially longer for applications.
In a clinical setting, time constraints are not as important as accuracy and reliability of results although excessive query times decrease the usefulness of such a tool for physicians in clinical practice.

% novelty
%LTQP algorithms are an active area of active research, but most of the work done has been with generalized algorithms and ,amy datastores with small amounts of data.
%I aim to adapt this querying approach to the specific domain of genomic and health data which has not been attempted before. 


\newcommand\WPcb{Algorithm incorporation of PGS data indexes and data vault summaries}
\subsubsection{Task~3.2: \WPcb}

I will look to innovate and improve performance by combining existing algorithms with strategies that leverage the unique structure of PGS data such as the use of pre-computed indexes, like the one generated for RDF-VCF conversion, as a guide for faster query processing.
% not totally sure how this will look...


\newcommand\WPcc{Privacy-preserving data vault summaries}
\subsubsection{Task~3.3: \WPcc}

%we want to protect patient data using strict authorization protocols
% but if we are making summaries or indexes of the private data, that process requires access to the personal data to produces those shortcuts
% a solution to limiting access to private data but still being able to create summaries is through Bloom filters for creating privacy-preserving summaries over encrypted data
Protecting the privacy of patient data includes restricting the number of vulnerable access points of that data exist.
For large numbers of pods aggregators can be utilized to improve query speed and efficiency by limiting the query to only relevant data sources.
For private genomic data, aggregators accessible outside of patient data vaults would infringe on the privacy of PGS data stored within patient data vaults.
By using a strategy that incorporates ...


\newcommand\WPcd{Data vaults as Beacon endpoints}
\subsubsection{Task~3.4: \WPcd}

To contribute to research that continues the expansion of PGS for clinical practice, I will make patient data vaults discoverable as Beacon endpoints.
The Beacon initiative is an attempt to increase the amount of genomic data available to researchers.
The federated network allows for the querying of all participating insititution databases, which are displayed to a central API as servers, through local execution of the query and transmission of the anonymized result to the requester.
Currently, all Beacon endpoints are centralized databases, thus establishing a workflow for the integration of decentralized data vaults would help the initiative expand with the industry past centralized storage strategies.
I will first attempt to make the data vaults discoverable by the Beacon API, which will be a user-controlled opt-in data sharing option.
Investigation into how Beacon queries will be executed will be performed in WP3.

I will assess how implementation of the algorithms developed and benchmarked for PGS data querying can be utilized for Beacon queries. 
First, I will create an interface for communication between the Solid data vault(s) and the Beacon API. 
Then, I will work to establish a methodology for converting a Beacon query into a SPARQL query that can be executed over patient data vaults.
In this querying, only data vaults that have opted-in to sharing data with reserachers should be discoverable, therefore, utilization of privacy-preserving summaries in aggregators will be heavily relied on.


\subsubsection{Risks}

benchmarks cannot be run because PGS data is too big

If these secure summaries cannot be ...

incorporating indexes and/or summaries in LTQP algos doesnt improve performance enough to be usable...

If the beacon connection does not work ...
beacon queries are not translatable to SPARQL or queries are too complex to be completed...


\newcommand\WPd{Consolidation and framework deployment}
\subsection{Component 4: \WPd}

The three components will be combined into a .....


\subsection{Work plan}
\smallskip

\noindent
My project consists of 4 work packages. 
This will be bundled into a Ph.D. dissertation for a final thesis defense.
Below Gantt-chart of the Ph.D. project on a quarterly basis.  
Each work package is split up into different tasks with a dedicated amount of time allocated to it. 
This will allow for a good time and project management. 

%have not gotten to editing this table yet
\begin{adjustwidth}{0cm}{0cm}
	\parindent 0pt
	\newcommand\duration[1]{\hfill\emph{#1~months}}
  
	\textbf{WP1:      \WPa  \duration{8}}
	\begin{itemize}
	  \item Task 1.1: \WPaa \duration{ 4}
	  \item Task 1.2: \WPab \duration{ 4}
	\end{itemize}
	\smallskip
  
	\textbf{WP2:      \WPb  \duration{10}}
	\begin{itemize}
	  \item Task 2.1: \WPba \duration{ 2}
	  \item Task 2.2: \WPbb \duration{ 4}
	  \item Task 2.3: \WPbc \duration{ 4}
	\end{itemize}
	\smallskip
	
	\textbf{WP3:      \WPc  \duration{20}}
	\begin{itemize}
	  \item Task 3.1: \WPca \duration{ 4}
	  \item Task 3.2: \WPcb \duration{ 12}
	  \item Task 3.3: \WPcc \duration{ 4}
	\end{itemize}
	\smallskip
	
	\textbf{WP4:      \WPd  \duration{ 6}}
\end{adjustwidth}

\noindent
I will undertake work packages and tasks as shown below in a Gantt chart.
The primary work packages of my Ph.D. are WP1 and WP3.
WP2 is a suporting work package and WP4 will be completed by combining all other work packages.
WP1 and WP3 are dependent, meaning that WP1 must be partially completed before WP3 can begin.
Thus, these work packages are planned sequentially, which provides me with knowledge of how data storage architecture could be leveraged for WP3.

The focus of WP1 is on storing and formatting PGS data.
The development of a workflow for setting up Solid data vaults and getting PGS data into those vaults is the first step (Task 1.1).
Once the PGS data is stored, investigation into data format conversion and data representation will be performed (Task 1.2).

For WP2, I will apply privacy protecting policies to stored PGS data and summaries of that data.
This task will utilize the Solid protocol for data policies within data vaults (Component 2).

In WP3, I will build on the work of WP1 and assess the query performance of LTQP algorithms on genomic data vaults.
I will start by benchmarking existing LTQP algorithms in a formal benchmarking study (Task 3.1).
Then, I will develop modified LTQP algorithms that use genomic indexes and data vault summaries to improve query efficiency (Task 3.2).
To further optimize query performance, I will experiment with the production of privacy preserving summaries stored in aggregators outside of data vaults (Task 3.3).

I will unify the three framework components into a web application (WP4) that will be deployed as a demonstration complete with documentation and a live presentation component. 
Throughout the previous work packages, I aim to publish incremental findings in high-impact journals and conferences.
For this, I will focus on journals such as the Semantic Web Journal, Journal of Healthcare Informatics Research, and the PLOS Digital Health Journal.
Furthermore, I will target conferences such as the International Semantic Web Conference, the Semantic Web Applications and Tools 4 Health Care and Life Sciences conference, and the European Conference on Computational Biology.

Aside from disseminating to the scientific community,
I will also community my research to the industrial community and wider public throughout the project (not included in the Gantt chart).
Concretely, I will write blog posts, publish videos, and interact with the greater community via X.


\bigskip

% Have not gotten to fixing the Gantt chart up yet...
\noindent
\begin{ganttchart}[
  x unit=11.4pt,
  y unit title=12pt,
  y unit chart=11pt,
  bar height=1,
  bar top shift=0,
  title height=1,
  group height=.1,
  group/.append style={draw=none,fill=none},
  vgrid={black!15},
  hgrid style/.style=black!50,
  bar label font=\it,
  title label font=\bf,
]{1}{36}
  \gantttitle{2023}{ 3}
  \gantttitle{2024}{12}
  \gantttitle{2025}{12}
  \gantttitle{2026}{ 9}
  \\
  \ganttset{title label font={}}
  \gantttitle{Q4}{3}
  \gantttitle{Q1}{3}\gantttitle{Q2}{3}\gantttitle{Q3}{3}\gantttitle{Q4}{3}
  \gantttitle{Q1}{3}\gantttitle{Q2}{3}\gantttitle{Q3}{3}\gantttitle{Q4}{3}
  \gantttitle{Q1}{3}\gantttitle{Q2}{3}\gantttitle{Q3}{3}
  \\
  
  \ganttgroup{WP1}{ 1}{13}\\
  \ganttset{bar/.append style={fill={rgb,255:red,220;green, 35;blue,  0}}}
  \ganttbar{T1.1}{1}{2}
  \ganttbar{    }{20}{21}
  \\
  \ganttbar{T1.2}{3}{3}
  \ganttbar{    }{7}{7}
  \ganttbar{    }{15}{15}
  \ganttbar{    }{22}{22}
  \ganttbar{    }{26}{26}
  \ganttbar{    }{32}{32}
  \\[grid]

  \ganttgroup{WP2}{ 1}{16}\\
  \ganttset{bar/.append style={fill={rgb,255:red, 87;green,157;blue, 28}}}
  \ganttbar{T2.1}{4}{6}
  \ganttbar{    }{8}{10}
  \\
  \ganttbar{T2.2}{12}{14}
  \ganttbar{    }{16}{17}
  \\[grid]

  \ganttgroup{WP3}{ 1}{10}\\
  \ganttset{bar/.append style={fill={rgb,255:red,  0;green,132;blue,209}}}
  \ganttbar{T3.1}{23}{25}
  \ganttbar{    }{27}{28}
  \\
  \ganttbar{T3.2}{30}{31}
  \ganttbar{    }{33}{34}
  \\[grid]

  \ganttset{bar/.append style={fill={rgb,255:red,255;green,149;blue, 14}}}
  \ganttbar{\bf WP4}{11}{11}
  \ganttbar{       }{18}{19}
  \ganttbar{       }{29}{29}
  \ganttbar{       }{35}{36}
\end{ganttchart}


\section{Strategic dimension and application potential}
% Aim for 1-2 page?
\begin{comment}
Elaborate the strategic dimension of your research, with regard to the 
(long-term) potential for innovative applications. 
Substantiate the PhD projectâ€™s strategic focus on economically relevant innovations. 

Justify how the chosen research approach (if successful) is the appropriate one to achieve the anticipated application(s) (potentially long term).

Elaborate the strategic importance of the potential applications to possible users (impact). 
Show how (if the project is successful) new products, services and/or processes may affect business of specific companies, a collective of companies and/or a sector and/or may be closely aligned with the Flemish science, technology and innovation transition priorities  (Flanders in transition. Priorities in Science, Technology and Innovation towards 2025) (socio-economic benefits). 

Societal impact should always be linked to a (in)direct (macro)economic benefit, e.g. cost reductions in health care, higher education level, environmental impact etc. should be positioned in an economic context.
\end{comment}
\smallskip

% personalized medicine --> more sequences
% sequences are expensive and sensitive
% for there to be more personalized medicine, sequence generation and maintenance needs to decrease
% sequence generation cost has been decreasing but storing it has not
% therefore we have a problem to solve
My Ph.D. project is strongly motivated by the potential economic and societal gains presented by personalized medicine. 
For all existing and future applications of genetically-informed precision health, patient genome sequence data in some form will be required.
In recent years, the cost of digital genome sequence generation has steadily decreased~\cite{wetterstrand_cost_2021}, but over that same time the cost of storing and maintaining the privacy of that data has not kept pace~\cite{}.
Thus, unintended barriers to scaling current clinical genomic workflows as well as to researching new workflows have been observed.

% there are different ways to solve the above problem but right now they cant happen (largely because of technological constraints)
% my framework allows us to solve the posed privacy <--> sharing problems 
% along with other cool features (connection to products purchased by the consumer / querying for clinicians) that could be built upon in the future
% generally my project is saying "if we store this stuff in a new way there are so many new possibilities for applications"
% this roughly equates to developing a new niche market (or even multiple niche markets)
% examples include: personal genomic products that can use your WGS, data linking to ANY kind of medical data, potential for being financially compensated for allowing your genome to be used for research, etc...
The the framework that will result from my Ph.D. will be uniquely positioned to compete with the current state-of-the-art intitiution-centric data storage systems due to the flexibility and cost efficiency it offers as a citizen-centric approach.
The approach accomplishes this cost efficiency though infrastructure for privacy preserving patient genomic data sharing, data policy customization, and integrated data querying capabilities.
Because most data is confined within a single health care institution, data sharing between institutions is an economic niche that is largely unfilled. 

The private genomic service industry dominated by companies such as 23andMe, Ancestry.com, sequencing.com, and others establishes that genomics data generation and storage holds importance to consumers for various personal and medical reasons. 
At the same time, hospital systems exclusively store and maintain all patient PGS data that is used for clinical applications. 
There is notable nuance between these two sectors including different forms of genomic data being generated, stored, and used, differing legal oversight concerning commercial genomic data and health data, and formatting differences between the genomic data stored. 
Regardless, in our modern age of big data, data duplication due to data siloing, energy waste due to computational demands during data regeneration, and intrinsic security concerns for modern data storage techniques are major economic inefficiencies of the current system. 

A hypothetical company that, in coordination with policy makers and regulatory bodies, creates a scalable storage and data sharing infrastructure for genomic data, which could also grow to include all patient health data in time, stands to greatly increase the efficiency of PGS data usage in healthcare. 
% boom Disruptive innovation. 
% New market, data no longer needed to be maintained by hospitals, a new chance for establishing standardization, new market for health data applicaitons, etc.
Such efficiency increases could help lower patient costs for specialized genetic tests, remove data management and administration from hospitals, thereby reducing costs, and establish a new market within which economic growth could result. 

% one of the great advantages of my framework is that it allows for the separation of clinically relevant data from a single health care institution. 
% doubtless, there will need to be regulatory presence in deploying a product version
% but, that is sort of built into the current project
% here I am presenting how the tools for the system COULD be put together and prove that within the constraints presented by health care data they CAN produce a functional system
% if it is directly translated into a project GREAT, but the more realistic goal is to provoke other ideas that improve the presented system
% the goal is to make more personalized medicine more doable, citizen-centric data control is the most attractive economic and ethical path toward that goal.
My project presented above is designed to present a proof-of-concept framework, both providing and demonstrating the technological foundations for the storage of PGS data in Solid pods, the controlling of access to that data on a granular level, the ability for that data to be queried, and exhibiting the accessibility of the stored PGS data to users, web applications, and medical tools in formats that can be used by both those currently in use and applications developed in the future. 
Such a framework will provide the outline of necessary implementation considerations from a technological perspective while also highlighting strengths and weaknesses of such a system that may be influential in attempts at scaling such an infrastructure. 
My project is also being undertaken in parallel with the European Virtual Human Twin (EDITH)~\cite{edith} initiative that aims at evolving the way medical data is stored to be increasingly citizen/patient centric both within Flanders as well as the greater European Union. 
The WE ARE project~\cite{weare} is another Flemish initiative exploring ways in which citizen-centric data stprage and ownership.


In the short-term, the project is being developed to be integrated into ongoing research and product development at VITO Digital Precision Health. 
Products aimed at improving the way drug prescription is practiced by using a genetic screening tool that leverages documented genetic predispositions to drug ineffectiveness are currently being developed to be connected to my framework of Solid pod stored PGS data. 
Additionally, connection to other known and widely-used workflows such as for NIPT and rare genetic disease screening is a primary goal for my project. 
Genomic data interoperability is of utmost importance for clinical application and is therefore a cornerstone of my project. 

The European Health Data Space (EHDS) aims to establish a reliable, interoperable, and secure environment for health data for all EU citizens~\cite{EHDS_2022}

Lastly, public perception is a crucial element to the economic growth of a product or sector. 
With personal data usage transparency as well as greater calls for digital data privacy protections becoming more important to the public, such considerations should also be priorities to how health data is managed. 
The existing system of genomic data storage for use in healthcare is prone to data leaks and heavily restricted patient transparency due to the central architecture of institution-centric data stores. 
With my proposed framework, patients would be more intimately connected to their data, potentially even having a say over to whom and what their data is visible. 
Such improved transparency, when paired with decreased risk of large-scale data leaks, is likely to be well-received by the general public. 
Such public support could help drive such a framework adoption to a larger scale such as nationally or even to be the standard for a system like the EU. 
This large scale goal, while nowhere near attainable in the near future, would present the greatest possible outcome for such a project and exhibit a somewhat unintuitive increase in greater genomic data privacy and shareability. 
In this scenario, there is also room for healthy competition within such a niche as various pod providers could offer hospital systems and educational institutions different rates for data storage and associated computation.


\section{References}
% Give an overview of the bibliographical references that are relevant for your research proposal. 
\smallskip
\printbibliography[heading=none]


\end{refsection}

\end{document}